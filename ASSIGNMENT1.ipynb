{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwtVH9ol2czNFSh9T5oKXL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303a51863/NLP/blob/main/ASSIGNMENT1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pr-XLuuB4z7J",
        "outputId": "e85eaa5c-0442-4dea-9b99-d14ba0124c39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.16.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.14.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.8.3)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re"
      ],
      "metadata": {
        "id": "F4HYHpIC62gv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"bbc_news.csv\")"
      ],
      "metadata": {
        "id": "FgvNt9I565Z9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"First 3 rows of dataset:\")\n",
        "print(df.head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJtC1DeT_RSG",
        "outputId": "1ce41074-bbba-4156-9eba-0809bf5ce40b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 3 rows of dataset:\n",
            "                                               title  \\\n",
            "0  Ukraine: Angry Zelensky vows to punish Russian...   \n",
            "1  War in Ukraine: Taking cover in a town under a...   \n",
            "2         Ukraine war 'catastrophic for global food'   \n",
            "\n",
            "                         pubDate  \\\n",
            "0  Mon, 07 Mar 2022 08:01:56 GMT   \n",
            "1  Sun, 06 Mar 2022 22:49:58 GMT   \n",
            "2  Mon, 07 Mar 2022 00:14:42 GMT   \n",
            "\n",
            "                                               guid  \\\n",
            "0  https://www.bbc.co.uk/news/world-europe-60638042   \n",
            "1  https://www.bbc.co.uk/news/world-europe-60641873   \n",
            "2      https://www.bbc.co.uk/news/business-60623941   \n",
            "\n",
            "                                                link  \\\n",
            "0  https://www.bbc.co.uk/news/world-europe-606380...   \n",
            "1  https://www.bbc.co.uk/news/world-europe-606418...   \n",
            "2  https://www.bbc.co.uk/news/business-60623941?a...   \n",
            "\n",
            "                                         description  \n",
            "0  The Ukrainian president says the country will ...  \n",
            "1  Jeremy Bowen was on the frontline in Irpin, as...  \n",
            "2  One of the world's biggest fertiliser firms sa...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_noisy(text):\n",
        "    return re.findall(r\"[\\nâ€¢]\", (text))"
      ],
      "metadata": {
        "id": "_f5-XPyO_XX7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['noisy_chars'] = df['description'].astype(str).apply(check_noisy)\n",
        "print(\"\\nNoisy characters detected in each row:\")\n",
        "print(df[['description', 'noisy_chars']].head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1O0Com8r_caC",
        "outputId": "a961edc8-279c-4f0e-e000-151f9aaf9a53"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Noisy characters detected in each row:\n",
            "                                         description noisy_chars\n",
            "0  The Ukrainian president says the country will ...          []\n",
            "1  Jeremy Bowen was on the frontline in Irpin, as...          []\n",
            "2  One of the world's biggest fertiliser firms sa...          []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "RwkIsprS_tDj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxpTwzHG_zQ-",
        "outputId": "8dda990b-f90d-4bcc-8657-1d4ff8885000"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "ps = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "1AOoxTz8_57O"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "# Function to clean, tokenize, stem, remove stop words\n",
        "def preprocess_nltk(text):\n",
        "    # Remove special characters and digits\n",
        "    text = re.sub(r'[^A-Za-z\\s]', '', str(text))\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    # Remove stopwords\n",
        "    tokens = [t for t in tokens if t not in stop_words]\n",
        "    # Stem tokens\n",
        "    stemmed = [ps.stem(t) for t in tokens]\n",
        "    return stemmed\n",
        "\n",
        "df['stemmed_tokens'] = df['description'].apply(preprocess_nltk)"
      ],
      "metadata": {
        "id": "dk5zppxA__uy"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "# Get top 10 frequent stemmed words\n",
        "all_stems = [stem for tokens in df['stemmed_tokens'] for stem in tokens]\n",
        "stem_freq = Counter(all_stems).most_common(10)\n",
        "\n",
        "print(\"\\nTop 10 frequent stemmed words:\")\n",
        "print(stem_freq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlY2Zx-BAFgk",
        "outputId": "a5c81558-a031-478e-bd9c-794744beabc7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 frequent stemmed words:\n",
            "[('say', 6397), ('bbc', 2408), ('england', 2338), ('year', 2251), ('world', 2170), ('peopl', 2021), ('first', 1909), ('new', 1894), ('win', 1747), ('uk', 1682)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Sample DataFrame (replace with your actual data)\n",
        "# df = pd.DataFrame({'description': [...]})\n",
        "\n",
        "def spacy_pipeline_pipe(texts):\n",
        "    docs = nlp.pipe(texts)  # Faster than calling nlp() on each string\n",
        "    result = []\n",
        "    for doc in docs:\n",
        "        tokens = [token.lemma_.lower() for token in doc\n",
        "                  if token.is_alpha and token.pos_ in [\"NOUN\", \"VERB\"]]\n",
        "        result.append(tokens)\n",
        "    return result\n",
        "\n",
        "# Apply optimized function\n",
        "df['lemmas'] = spacy_pipeline_pipe(df['description'].astype(str))"
      ],
      "metadata": {
        "id": "k3WkicyGAkXN"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get top 10 frequent lemmas\n",
        "all_lemmas = [lemma for tokens in df['lemmas'] for lemma in tokens]\n",
        "lemma_freq = Counter(all_lemmas).most_common(10)\n",
        "\n",
        "print(\"\\nTop 10 frequent lemmas:\")\n",
        "print(lemma_freq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFdr1WsOAqx6",
        "outputId": "3e7d96ba-c16a-4aa2-b0ab-35d5fc952158"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 frequent lemmas:\n",
            "[('say', 7138), ('year', 2994), ('people', 2018), ('win', 1985), ('take', 1646), ('have', 1527), ('day', 1505), ('make', 1475), ('time', 1210), ('find', 1148)]\n"
          ]
        }
      ]
    }
  ]
}